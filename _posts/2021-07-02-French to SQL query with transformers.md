---
layout: post
title: French to SQL query API using transformers | Fast-Api | Docker 
subtitle: Tired to write down SQL queries ? Lazy to learn SQL ? This article might be for you...
cover-img: /assets/img/
thumbnail-img: /assets/img/article french sql query logo.png
share-img: /assets/img/
tags: [SQL, Transformers, Hugging face, query, fast-api, docker]

---
## Introduction ##

Il y a quatre ans, un papier scientifique entraina une profonde r√©volution dans le milieu de l'intelligence artificielle et plus sp√©cifiquement dans le deep learning. En effet, consid√©r√© comme une v√©ritable avanc√©e, le papier [Attention is all you need (2017)](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) de Vaswani, et al., d√©veloppa le concept d'*attention* permettant une am√©lioration significative des performances des neural networks utilis√©s jusqu'√† lors pour des t√¢ches de traitement naturel du language (NLP = Naturel Language Processing). Ainsi, nacquirent les Transformers. Non, je ne parle pas des auto-bots et decepticons se livrant une lutte sans merci et ayant la facult√© de se transformer en voitures, mais bel et bien de neural networks reposant sur le concept d'attention, et tr√®s puissant en  NLP. Petite anecdote, si vous avez remarquez une am√©lioration dans la traduction g√©n√©r√©e par Google trad au cours de cette p√©riode,maintenant vous savez que se sont les transformers √† l'oeuvre !

Depuis la publication, les d√©couvertes et avanc√©es dans l'√©tude des transformers se sont consid√©rablement enrichient, contribuant ainsi au d√©veloppement d'un nombre incroyable de mod√®les utilis√©s pour la r√©solution de t√¢ches de NLP telles que la classification de phrases, l'analyse de sentiments, la traduction mais aussi la g√©n√©ration de texte (Essayez [AI Dungeon](https://play.aidungeon.io/main/landing) pour voir la puissance des mod√®les GPT-2 & 3 et surtout quelques heures de fun) et autres. Gr√¢ce √† [Hugging Face] ü§ó, soci√©t√© francaise üá´üá∑ fond√© en 2016 par Cl√©ment Delangue et Julien Chaumond, il est d√©sormais possible d'impl√©menter le State-of-the-Art du NLP en toute simplicit√©. En effet,avec la cr√©ation de la librairie [transformers](https://huggingface.co/transformers/), de nombreux mod√®les pr√©-entrain√©s sur des t√¢ches sp√©cifiques,avec possibilit√© de les fine-tuner, peuvent √™tre utilis√©s sans etre un crack sur le fonctionnement de ce type de neural network.

Un jour, apr√®s avoir scroll√© de nombreuses minutes sur Linkedin, je me retrouva devant un post de Hugging Face qui faisait √©tat des capacit√©s du mod√®le GPT-Neo, cousin open-source de GPT-3. Ce post m'intrigua fortement, d'autant plus qu'il √©tait mention de la possibilit√© de traduire du texte en requetes SQL. En tant que Data Analyst, le language SQL tient une place fondamentale dans mon m√©tier. Le SQL √©tant partout, il m'est d√©ja arriv√© d'imaginer un monde o√π il serait possible de requeter ses donn√©es directement (e.g: "Quels sont les 10 magasins ayant le chiffre d'affaire le plus elev√© dans l'ordre d√©croissant ?") sans passer par le language SQL. Et bien je crois qu'aujourd'hui ce monde est √† port√© de main et que de plus en plus de solution permettant de requeter des donn√©es de facon textuelles ( = no SQL) seront amen√©es √† etre developp√©es. En effet, m√™me si le SQL est un language extremement r√©pandu, utilis√© non pas seulement par des individus dans la data, il existe bien des personnes n'ayant pas de notions en SQL ( ou qui haissent le language type code) qui pourraient √™tre amen√©es √† r√©aliser des requetes. Ddans ce contexte, 

Bon, tr√™ve de bavardage, il est temps de passer √† l'action et je crois que vous voyez ou je veux en venir...L'API pour traduire du texte en anglais en SQL existe d√©ja (Testez la [ici](https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL) !), l'id√©e n'est pas de la recr√©er, cela n'aurait aucun interet. Mais...en bon francais que je suis, je me suis dit: "Hey ! Mais ca serait vraiment cool de pouvoir directement ecrire en francais üá´üá∑!". Cocorico, j'ai d√©cid√© de cr√©er une API toute simple qui prend en input du texte francais pour la convertir en requete SQL et de la d√©ployer. Voyons tout de suite comment nous allons nous y prendre !

## La recette de cuisine pour l'API ##

Pour d√©buter, vous aurez besoin :
1. 3 oeufs
2. 100 g de fa....Ah d√©sol√©, c'est la recette du gateau au chocolat marmiton ca...

Non, plus s√©rieusement, voici ce dont nous allons vraiment avoir besoin:

### Transformers ### 

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F1200%2F1*Bp8K-_PJrG2NQxLlzk7hlw.png&f=1&nofb=1)

Comme mentionn√© auparavant, nous allons utilis√© la librairie **Transformers** de Hugging Face. La librairie est indispensable puisqu'elle contient les mod√®les pr√©-entrain√©s que nous allons utiliser pour la traduction du francais en SQL.. Pour l'installation, si vous avez deja Tensorflow 2.0 et/ou PyTorch, vous pouvez directement l'installer avec pip (Pour plus de pr√©cisions, la doc d'installation est consultable [ici](https://huggingface.co/transformers/installation.html):
```console
pip install transformers
```
Pour v√©rifier que l'installation s'est bien pass√©, vous pouvez runner la commande suivante dans votre terminal bash:
```console
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
```
Vous devriez voir appara√Ætre ceci:
```console
[{'label': 'POSITIVE', 'score': 0.9998704791069031}]
```

### FastApi ###

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F1023%2F1*du7p50wS_fIsaC_lR18qsg.png&f=1&nofb=1)

[FastApi](https://fastapi.tiangolo.com/) est un framework web qui, comme son nom l'indique, va nous permettre de cr√©er rapidement des API ultra-performante. En trois mots, FastApi c'est: Rapide, simple et robuste. La rapidit√© de FastAPI est possible gr√¢ce √† Pydantic, Starlette et Uvicorn. Pydantic est utilis√© pour la validation des donn√©es et Starlette pour l'outillage, ce qui le rend extr√™mement rapide par rapport √† Flask et lui conf√®re des performances comparables √† celles des API Web √† haut d√©bit en Node ou Go. Il s'agit d'un cadre innovant construit sur Starlette et Uvicorn. Starlette est un framework/toolkit ASGI l√©ger, id√©al pour cr√©er des services asynchrones √† haute performance. Uvicorn est un serveur ASGI rapide comme l'√©clair, construit sur uvloop et httptools. 

Pour installer FastApi, rien de plus simple:
```console
pip install fastapi uvicorn[standard]
```

### Docker ###

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn.1min30.com%2Fwp-content%2Fuploads%2F2018%2F04%2FLogo-Docker.jpg&f=1&nofb=1)

Bon, je pense que je n'ai pas besoin de pr√©senter Docker en long et en large. Pour faire court, Docker va nous permettre de  "containeriser"  notre code ainsi que ses d√©pendances (e.g. Transformers, FastApi) afin notre API puisse etre execut√© sur n'importe quel serveur. Pour cela, nous allons cr√©er un DOCKERFILE et builder l'image DOCKER.

Si Docker n'est pas d√©ja install√©, je vous renvoie √† la doc, qui est tr√®s bien ecrite : [Get Docker](https://docs.docker.com/get-docker/) 
 
## Cr√©ation de l'API ##

Maintenant que nous avons pass√© en revu tout ce dont nous avions besoin pour cr√©er notre API et in fine, la d√©ployer, il est temps de passer √† l'action! Vous allez voir qu'en quelques lignes de code la magie va op√©rer. üßôüèª‚Äç‚ôÄÔ∏è  

### Cr√©ation du script ###

Dans cette partie nous allons montrer comment cr√©er l'API √©tape par √©tape. 

1. Importer les librairies

importer dans notre petit script python les librairies dont nous avons besoin pour notre API. Dans l'ordre, on import tout d'abord FastApi et uvicorn, puis les auto classes  **AutoModelWithLMHead** et **AutoTokenizer** de la librairie transformers que nous utiliserons juste apr√®s et que j'expliquerai plus en d√©tails. La librairie logging n'est pas essentielle ici, elle permet juste d'√©mettre des messages suites √† des √©ven√®ments et ainsi r√©soudre des anomalies.
```py
# Import packages:

from fastapi import FastAPI
import uvicorn
from transformers import AutoModelWithLMHead, AutoTokenizer
#import logging
```
2. Cr√©er l'instance FastApi

Une fois les librairies import√©es, la premi√®re chose √† faire est d'instancier notre application. Pour cela, rien de plus simple :
```py
# Instanciate the app:

app = FastAPI(title='French to SQL translation API ü§ó', description='API for SQL query translation from french text using Hugging Face transformers')

#my_logger = logging.getLogger()
#my_logger.setLevel(logging.DEBUG)
#logging.basicConfig(level=logging.DEBUG, filename='logs.log')
```
FastApi est une classe python qui contient l'ensemble des fonctionnalit√©s pour l'API. De plus, par convention on appellera la variable 'app' mais vous pouvez l'appeler comme bon vous semble. Pour finir, il est possible de renseigner dans les param√®tres le titre ainsi qu'une br√®ve description de l'application, ce qui permettra aux utilisateurs de savoir √† quoi sert l'API.

3. Instanciate transformers models

Cette √©tape est la plus importante dans le script puisque c'est ici que nous allons telecharger les mod√®les pr√©-entrain√©s et les tokenizers associ√©s et les instancier. Pour cela, on utilise les deux classes import√©es pr√©c√©demment:

- AutoModelWithLMHead: Classe de mod√®le qui sera instanci√©e lorsque l'on utilisera la m√©thode de classe AutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path). Il existe une tr√®s grande vari√©t√© de mod√®les qui peuvent etre t√©l√©charger, chacun ayant des sp√©cificit√©s et permettant de r√©sourdre des probl√©matiques diff√©rentes. La liste des mod√®les est consultable [ici](https://huggingface.co/transformers/v3.0.2/model_summary.html) !

- AutoTokenizer: Classe de tokenizer qui sera instanci√©e lorsque l'on utilisera la m√©thode de classe AutoTokenizer.from_pretrained(pretrained_model_name_or_path). Le tokenizer utilis√© est celui mentionn√© par l'utilisateur dans la m√©thode from_pretrained ( e.g. distillert, roberta, t5,...) Petit rappel conernant la tokenization,l'objectif du tokenizer est tout simplement de pr√©traiter le texte. Il va diviser le texte en mots (ou parties de mots, symboles de ponctuation, etc.) que l'on appelle **tokens**. Lors de l'utilisation d'un mod√®le, il faut s'assurer que le tokenizer instanci√© correspond au tokenizer ayant √©t√© utilis√© pour entrainer le mod√®le.
```py
#Download and instanciate vocabulary and Fr-to-En model :
model_trad_fr_to_eng = AutoModelWithLMHead.from_pretrained("Helsinki-NLP/opus-mt-fr-en")
tokenizer_translation = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-fr-en")

#Download and instanciate vocabulary and En-to-SQL model :
tokenizer_sql = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
model_sql = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
```
Le code ci-dessus nous permet donc de telecharger et instancier dans un premier temps le mod√®le [opus-mt-fr-en](https://huggingface.co/Helsinki-NLP/opus-mt-fr-en). Ce mod√®le va tout simplement nous permettre de convertir du francais en anglais. Puis on t√©l√©charge et instancie le mod√®le [t5-base-finetuned-wikiSQL](https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL qui va convertire le texte anglais en SQL.

4.D√©finir le *path operation decorator*:

Cette √©tape va faire en sorte que l'API puisse r√©aliser certaines actions ( dans notre cas, traduire le texte en SQL) en communiquant avec elle via des m√©thodes de requetes HTTP. Pour parvenir √† notre fin, on va renseigner √† FastApi le type de m√©thode (e.g. POST, GET, DELETE, PUT,...) et le chemin ( L'endroit/endpoint o√π se fait la requete). Voici un exemple d'operation que l'on pourait r√©aliser:
```py
@app.get('/')
def get_root():

    return {'Message': 'Welcome to the french SQL query translator !'}
```
Le ``` @app.get('/')``` dit √† FastApi que la fonction juste en dessous est charg√©e de traiter les requetes qui vont vers le chemin ```/``` et qui utilisent la m√©thode GET, ce qui renverra le dict ```{'Message': 'Welcome to the french SQL query translator !'}```

Maintenant que nous comprenons mieux comment r√©aliser des op√©rations, nous allons pouvoir √©crire la fonction qui va traduire le texte en francais en SQL: 
```py
@app.get('/get_query/{query}', tags=['query'])
async def text_to_sql_query(query:str):
    
    '''This function allows to convert french text to a SQL query using opus-mt-fr-en transformer for text translation and a t5 base finedtuned on wikiSQL for english to SQL traduction'''
    
    # Encoding: Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.
    # Decoding: Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special tokens and clean up tokenization spaces.
   
    
    inputs_trad = tokenizer_translation.encode(query, return_tensors="pt")
    outputs_trad = model_trad_fr_to_eng.generate(inputs_trad, max_length=600, num_beams=4, early_stopping=True)
    
    text_trad = tokenizer_translation.decode(outputs_trad[0]).replace('<pad>','')

    text_to_convert_query = "translate English to SQL: %s </s>" % text_trad
    features = tokenizer_sql([text_to_convert_query], return_tensors='pt')

    output_sql = model_sql.generate(input_ids=features['input_ids'], 
                attention_mask=features['attention_mask'])

    sql_query = tokenizer_sql.decode(output_sql[0]).replace('<pad>','').replace('</s>','')

    return { 'SQL QUERY' : sql_query} 
```
Ce que l'on fait ici est relativement simple √† comprendre. Concernant la fonction en elle-meme, cette derni√®re prend en argument le texte francais, que j'ai d√©sign√© ici par ```query```.Au passage vous pouvez noter que dans le path de la m√©thode get on retrouve notre ```query``` entre ```{}``` pour indiquer √† l'utilisateur qu'il a directement la possibilit√© de rentrer directement sa requ√™te version texte francais dans l'url.

Comme nous l'avons dit pr√©c√©demment, on cherche √† convertir le texte francais en anglais puis de l'anglais vers le SQL. La proc√©dure √† r√©aliser est la m√™me dans les deux cas:
- Encodage: On encode le texte avec la methode ```encode```. La ```string``` est convertit en dictionnaire de la forme suivante au sein duquel la list d'integer repr√©sente les index des tokens:
```py
{'input_ids': [101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 100, 19081, 3075, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```
- Generation: G√©n√®re les index des tokens pour la s√©quence que l'on cherche √† obtenir √† partir des index obtenus par le Tokenizer et l'utilisation du mod√®le pr√©-entrain√©.
- D√©codage: D√©code les index des tokens en une nouvelle string.

Pour conclure cette partie j'insiste sur le fait que la fonction doit renvoyer un ```dict```.

5. Runner l'API

On arrive  enfin √† l'√©tape finale qui va tout simplement consister √† faire tourner en local notre API sur un serveur Uvicorn. Pour cela, il existe deux possibilit√©s.
Vous pouvez rajouter dans le script ces 2 lignes de code:
```py
# Running the API on our local network:

if __name__ == '__main__':    
    uvicorn.run(app, host='127.0.0.1', port=8000)
```
Ou bien, vous pouvez directement lancer le serveur dans le terminal:
```console
uvicorn french_text_to_sql_query:app --reload
```
Au passage,voici le script au complet:
```py
# Import packages 
import uvicorn
import logging
from fastapi import FastAPI
from transformers import AutoModelWithLMHead, AutoTokenizer

app = FastAPI(title='French to SQL translation API ü§ó', description='API for SQL query translation from french text using Hugging Face transformers')

my_logger = logging.getLogger()
my_logger.setLevel(logging.DEBUG)
logging.basicConfig(level=logging.DEBUG, filename='logs.log')

model_trad_fr_to_eng = AutoModelWithLMHead.from_pretrained("Helsinki-NLP/opus-mt-fr-en")

tokenizer_translation = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-fr-en")

tokenizer_sql = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")

model_sql = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")

@app.get('/')
def get_root():

    return {'Message': 'Welcome to the french SQL query translator !'}

@app.get('/get_query/{query}', tags=['query'])
async def text_to_sql_query(query:str):
    
    '''This function allows to convert french text to a SQL query using opus-mt-fr-en transformer for text translation and a t5 base finedtuned on wikiSQL for english to SQL traduction'''
   

    inputs_trad = tokenizer_translation.encode(query, return_tensors="pt")
    outputs_trad = model_trad_fr_to_eng.generate(inputs_trad, max_length=600, num_beams=4, early_stopping=True)

    text_trad = tokenizer_translation.decode(outputs_trad[0]).replace('<pad>','')

    text_to_convert_query = "translate English to SQL: %s </s>" % text_trad
    features = tokenizer_sql([text_to_convert_query], return_tensors='pt')

    output_sql = model_sql.generate(input_ids=features['input_ids'], 
                attention_mask=features['attention_mask'])

    sql_query = tokenizer_sql.decode(output_sql[0]).replace('<pad>','').replace('</s>','')

    return { 'SQL QUERY' : sql_query} 

if __name__ == '__main__':    
    uvicorn.run(app, host='127.0.0.1', port=8000)
```
Une fois tout ceci r√©alis√©, notre script est termin√© et nous n'avons plus qu'√† le faire tourner. Si tout fonctionne correctement, vous devriez voir apparaitre ceci dans votre terminal :
```console
INFO:     Started server process [31847]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:33262 - "GET / HTTP/1.1" 200 OK
```
**Attention**: L'execution peut prendre un peu de temps selon votre connexion internet car il faut dans un premier temps t√©l√©charger les mod√®les.

Il est d√©sormais temps de se rendre sur notre API et de la tester ! Pour cela nous allons nous rendre au dashboard FastApi qui va nous permettre d'envoyer des requ√™tes √† l'API: [http://127.0.0.1:8000/docs#/](http://127.0.0.1:8000/docs#/)

![](https://user-images.githubusercontent.com/52154100/125428785-3cd376b1-667b-49ad-a92b-e4a53f97365b.png)

6. Test de l'API

Le moment de verit√© est enfin arriv√© ! Pour v√©rifier que l'API fonctionne nous allons essayer avec une requete relativement simple du type ```selectionner les magasins ayant un chiffre d'affaire sup√©rieur √† 100000``` ce qui se traduirait en SQL par la query ```SELECT shops FROM table WHERE turnover > 100 000```. En effet, tout cela reste relativement exp√©rimental donc ne soyez pas surpris si la query renvoy√©e n'est pas exactement se dont vous vous attendiez. Mais tout cela reste quand meme assez prometteur pour la suite et amusant(enfin c'est mon avis).

![](https://user-images.githubusercontent.com/52154100/125432056-2a2ef1cd-2e27-4200-b17f-eb928c313555.png)

Comme vous le voyez, j'ai directement execut√© la requ√™te dans le dashboard de FastApi (mais vous pouvez tr√®s bien l'ex√©cuter dans le terminal) qui nous renvoie ceci:
```console
{
  "SQL QUERY": " SELECT Stores FROM table WHERE Turnover > 100000"
}
```


