---
layout: post
title: French to SQL query API using transformers | Fast-Api | Docker 
subtitle: Fatigu√© d'√©crire des requ√™tes SQL ? Flemme d'apprendre le SQL ? Cet article peut vous interesser...
cover-img: /assets/img/background_api_sql_query.png
thumbnail-img: /assets/img/french_sql_api_logo.png
share-img: /assets/img/
tags: [SQL, Transformers, Hugging face, query, fast-api, docker]

---
## Introduction ##

Il y a quatre ans, un papier scientifique entra√Æna une petite r√©volution dans le milieu de l'IA. Consid√©r√© comme une v√©ritable avanc√©e, le papier [Attention is all you need (2017)](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) de Vaswani, et al., d√©veloppa le concept d'**attention**. Entrainant dans son sillage une am√©lioration des performances des r√©seaux de neurones utilis√©s pour le NLP (Naturel Language Processing) (les RNN), naquirent √† la suite les Transformers. Non, je ne parle pas des auto-bots et decepticons se livrant √† une lutte sans merci, mais bel et bien de neural networks reposant sur le concept d'attention, et √©tant particuli√®rement efficaces pour le NLP. Petite anecdote, si vous avez remarquez une am√©lioration dans la traduction g√©n√©r√©e par Google trad au cours de cette m√™me p√©riode, vous savez d√©sormais que les transformers sont √† l'≈ìuvre !

Depuis cette fameuse publication, les avanc√©es sur les transformers n'ont cess√©es de s'enrichir, contribuant ainsi √† l'apparition d'un nombre incroyable de mod√®les impliqu√©s dans la r√©solution de t√¢ches NLP aussi diverses que vari√©es. On donnera comme exemple la classification de phrases, l'analyse de sentiments, la traduction mais aussi la g√©n√©ration de texte (Essayez [AI Dungeon](https://play.aidungeon.io/main/landing) pour voir la puissance des mod√®les GPT-2 & 3 et surtout quelques heures de fun) et autres. Gr√¢ce √† [Hugging Face] ü§ó, soci√©t√© fran√ßaise üá´üá∑ fond√© en 2016 par *Cl√©ment Delangue* et *Julien Chaumond*, il est d√©sormais d‚Äôacc√©der √† la pleine puissance des transformers, et ceci en toute simplicit√©. En effet, avec la librairie [transformers](https://huggingface.co/transformers/), de nombreux mod√®les pr√©-entrain√©s sont mis √† disposition. 

## Contexte ##

En scrollant de nombreuses minutes sur LinkedIn, je me suis un jour retrouv√© devant un post de Hugging Face qui faisait √©tat des capacit√©s du mod√®le GPT-Neo, cousin open-source de GPT-3. Ce post m'intrigua puisqu'il mentionna la possibilit√© de traduire du texte en requ√™te SQL. En tant que Data Analyst, le SQL tient une place fondamentale dans mon m√©tier, je dirai m√™me qu'il est partout. Ce post tomba √† pic car je m‚Äô√©tais d√©j√† demand√© s‚Äôil existait un syst√®me/appli permettant de r√©aliser des requ√™tes ¬´ textuelles ¬ª (ex. : "Quels sont les 10 magasins ayant le chiffre d'affaire le plus √©lev√© dans l'ordre d√©croissant ?"). M√™me si le SQL est un langage extr√™mement r√©pandu et largement utilis√© pour acc√©der aux donn√©es,on peut imaginer qu'une application permettant de convertir du texte en requ√™te SQL pourrait trouver son utilit√© chez les personnes n'ayant pas/peu de notions en SQL.

Vous l‚Äôauriez compris en lisant le titre de cet article, ce post m‚Äôa donn√© une id√©e. Bien que L'API pour traduire de l‚Äôanglais en SQL existe d√©j√† (Testez la [ici](https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL) !), cette derni√®re n‚Äôexiste pas pour le fran√ßais üá´üá∑ ! Cocorico, nous allons cr√©er une API toute simple qui prendra en input du texte fran√ßais pour la convertir en requ√™te SQL, et of course, nous la d√©plorerons. Tr√™ve de bavardage, il est temps de passer √† l'action üí™.

## La recette de cuisine pour l'API ##

Pour d√©buter, vous aurez besoin :
1. 3 ≈ìufs
2. 100 g de fa....Ah d√©sol√©, c'est la recette du g√¢teau au chocolat marmiton √ßa...

Non, plus s√©rieusement, voici ce dont nous allons vraiment avoir besoin :

### Transformers ü§ó ### 

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F1200%2F1*Bp8K-_PJrG2NQxLlzk7hlw.png&f=1&nofb=1)

Comme mentionn√© au dessus, nous allons utiliser la librairie **Transformers** de Hugging Face. La librairie est indispensable puisqu'elle contient les mod√®les pr√©-entrain√©s que nous allons utiliser pour la traduction du fran√ßais en SQL. Pour l'installation, si vous avez d√©j√† Tensorflow 2.0 et/ou PyTorch, vous pouvez directement l'installer avec pip (Pour plus de pr√©cisions, la doc d'installation est consultable [ici](https://huggingface.co/transformers/installation.html):
```console
pip install transformers
```
Pour v√©rifier que l'installation s'est bien pass√©, vous pouvez lancer la commande suivante dans votre terminal bash:
```console
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
```
Vous devriez voir appara√Ætre ceci :
```console
[{'label': 'POSITIVE', 'score': 0.9998704791069031}]
```
### FastApi ‚ö°Ô∏è ###

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F1023%2F1*du7p50wS_fIsaC_lR18qsg.png&f=1&nofb=1)

[FastApi](https://fastapi.tiangolo.com/) est un framework web qui, comme son nom l'indique, va nous permettre de cr√©er rapidement des API ultra-performante. En trois mots, FastApi c‚Äôest : **Rapide**, **simple** et **robuste**. La rapidit√© de FastAPI est possible gr√¢ce √† Pydantic, Starlette et Uvicorn. Pydantic est utilis√© pour la validation des donn√©es et Starlette pour l'outillage, ce qui le rend extr√™mement rapide par rapport √† Flask et qui lui conf√®re des performances comparables √† celles des API Web √† haut d√©bit en Node ou Go. Starlette est un framework/toolkit ASGI l√©ger, id√©al pour cr√©er des services asynchrones √† haute performance. Uvicorn est un serveur ASGI rapide comme l'√©clair, construit sur uvloop et httptools. 

Pour installer FastApi, rien de plus simple :
```console
pip install fastapi uvicorn[standard]
```

### Docker  üêã  ###

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn.1min30.com%2Fwp-content%2Fuploads%2F2018%2F04%2FLogo-Docker.jpg&f=1&nofb=1)

Je pense que je n'ai pas vraiment besoin de pr√©senter Docker tant il est populaire. Pour rappel, Docker va nous permettre de ¬´ containeriser ¬ª  notre code ainsi que ses d√©pendances (ex . : Transformers, FastApi) afin notre API puisse √™tre ex√©cut√©e sur n'importe quel serveur. 

Si vous n‚Äôavez pas Docker install√©, je vous renvoie √† la doc, tr√®s bien √©crite : [Get Docker](https://docs.docker.com/get-docker/) 
 
## Cr√©ation de l'API ##

Maintenant que nous avons pass√© en revu tout ce dont nous avions besoin pour cr√©er notre API et in fine, la d√©ployer, nous allons pouvoir rentrer dans le vif du sujet ! Vous allez voir qu'en quelques lignes de code la magie va op√©rer. üßôüèª‚Äç‚ôÄÔ∏è  


### Cr√©ation du script ###

Dans cette partie nous allons montrer comment cr√©er l'API √©tape par √©tape. 

1. Importer les librairies

Pour commencer, il faut Importer les librairies dont nous avons besoin. Dans l'ordre, on importe tout d'abord **FastApi** et **uvicorn**, puis les auto classes **AutoModelWithLMHead** et **AutoTokenizer** de la librairie transformers que nous utiliserons juste apr√®s, et que j'expliquerai plus en d√©tails. La librairie logging n'est pas essentielle ici, elle permet juste d'√©mettre des messages en cas d‚Äôanomalies.
```py
# Import packages:

from fastapi import FastAPI
import uvicorn
from transformers import AutoModelWithLMHead, AutoTokenizer
#import logging
```
2. Cr√©er l'instance FastApi

Une fois les librairies import√©es, on instancie notre application. Pour cela, rien de plus simple :
```py
# Instanciate the app:

app = FastAPI(title='French to SQL translation API ü§ó', description='API for SQL query translation from french text using Hugging Face transformers')

#my_logger = logging.getLogger()
#my_logger.setLevel(logging.DEBUG)
#logging.basicConfig(level=logging.DEBUG, filename='logs.log')
```
FastApi est une classe python qui contient l'ensemble des fonctionnalit√©s pour l'API. De plus, par convention on appellera la variable 'app' mais vous pouvez l'appeler comme bon vous semble. Pour finir, il est possible de renseigner dans les param√®tres le titre ainsi qu'une br√®ve description de l'application, ce qui permettra aux utilisateurs de savoir √† quoi sert l'API.

3. T√©l√©charger et instancier les mod√®les transformers 

Cette √©tape est tr√®s importante dans le script puisque c'est ici que nous allons t√©l√©charger les mod√®les pr√©-entrain√©s et les tokenizers associ√©s et les instancier. Pour cela, on utilise les deux classes pr√©c√©demment import√©es :

- **AutoModelWithLMHead**: Classe de mod√®le qui sera instanci√©e lorsque l'on utilisera la m√©thode de classe AutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path). Il existe une tr√®s grande vari√©t√© de mod√®les qui peuvent √™tre t√©l√©charg√©s, chacun ayant des sp√©cificit√©s et permettant de r√©soudre des probl√©matiques diff√©rentes. La liste des mod√®les est consultable [ici](https://huggingface.co/transformers/v3.0.2/model_summary.html).

- **AutoTokenizer**: Classe de tokenizer qui sera instanci√©e lorsque l'on utilisera la m√©thode de classe AutoTokenizer.from_pretrained(pretrained_model_name_or_path). Le tokenizer utilis√© est celui mentionn√© par l'utilisateur dans la m√©thode from_pretrained (ex. : distillert, roberta, t5,...) Petit rappel concernant la tokenization, l'objectif du tokenizer est tout simplement de pr√©traiter le texte. Il va diviser le texte en mots (ou parties de mots, symboles de ponctuation, etc.) que l'on appelle **tokens**. A retenir, lors de l'utilisation d'un mod√®le il faut s'assurer que le tokenizer instanci√© correspond au tokenizer ayant √©t√© utilis√© pour entrainer le mod√®le.

```py
#Download and instanciate vocabulary and Fr-to-En model :
model_trad_fr_to_eng = AutoModelWithLMHead.from_pretrained("Helsinki-NLP/opus-mt-fr-en")
tokenizer_translation = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-fr-en")

#Download and instanciate vocabulary and En-to-SQL model :
tokenizer_sql = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
model_sql = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
```

Le code ci-dessus nous permet donc de t√©l√©charger et instancier dans un premier temps le mod√®le [opus-mt-fr-en](https://huggingface.co/Helsinki-NLP/opus-mt-fr-en). Ce mod√®le va tout simplement nous permettre de convertir du francais en anglais. Puis on t√©l√©charge et instancie le mod√®le [t5-base-finetuned-wikiSQL](https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL qui va convertir le texte anglais en SQL.

4.D√©finir le *path operation decorator*:

Cette √©tape va faire en sorte que l'API puisse r√©aliser certaines actions (dans notre cas, traduire le texte en SQL) en communiquant avec elle via des m√©thodes de requ√™tes HTTP. Pour parvenir √† notre fin, on va renseigner √† FastApi le type de m√©thode (ex. : POST, GET, DELETE, PUT,) et le chemin (L‚Äôendroit/endpoint o√π se fait la requ√™te). Voici un exemple d'op√©ration que l'on pourrait r√©aliser:

```py
@app.get('/')
def get_root():

    return {'Message': 'Welcome to the french SQL query translator !'}
```

Le ``` @app.get('/')``` dit √† FastApi que la fonction juste en dessous est charg√©e de traiter les requ√™tes qui vont vers le chemin ```/``` et qui utilisent la m√©thode GET, ce qui renverra le dict ```{'Message': 'Welcome to the french SQL query translator !'}```

Maintenant que nous comprenons mieux comment r√©aliser des op√©rations, nous allons pouvoir √©crire la fonction qui va traduire le texte fran√ßais en SQL:

```py
@app.get('/get_query/{query}', tags=['query'])
async def text_to_sql_query(query:str):
    
    '''This function allows to convert french text to a SQL query using opus-mt-fr-en transformer for text translation and a t5 base finedtuned on wikiSQL for english to SQL traduction'''
    
    # Encoding: Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.
    # Decoding: Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special tokens and clean up tokenization spaces.
   
    inputs_trad = tokenizer_translation.encode(query, return_tensors="pt")
    outputs_trad = model_trad_fr_to_eng.generate(inputs_trad, max_length=600, num_beams=4, early_stopping=True)
    
    text_trad = tokenizer_translation.decode(outputs_trad[0]).replace('<pad>','')

    text_to_convert_query = "translate English to SQL: %s </s>" % text_trad
    features = tokenizer_sql([text_to_convert_query], return_tensors='pt')

    output_sql = model_sql.generate(input_ids=features['input_ids'], 
                attention_mask=features['attention_mask'])

    sql_query = tokenizer_sql.decode(output_sql[0]).replace('<pad>','').replace('</s>','')

    return { 'SQL QUERY' : sql_query} 
```

Ce que l'on fait ici est relativement simple √† comprendre. Concernant la fonction en elle-m√™me, cette derni√®re prend en argument le texte fran√ßais, que j'ai d√©sign√© ici par ```query```.Au passage vous pouvez noter que dans le path de la m√©thode get on retrouve notre ```query``` entre ```{}``` pour indiquer √† l'utilisateur qu'il a directement la possibilit√© de rentrer directement sa requ√™te version texte fran√ßais dans l'url.

Comme nous l'avons dit pr√©c√©demment, on cherche √† convertir le texte fran√ßais en anglais puis de l'anglais vers le SQL. La proc√©dure √† r√©aliser est la m√™me dans les deux cas :
- Encodage : On encode le texte avec la m√©thode ```encode```. La ```string``` est convertit en dictionnaire de la forme suivante au sein duquel la liste d‚ÄôInteger repr√©sente les index des tokens:
```py
{'input_ids': [101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 100, 19081, 3075, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```
- G√©n√©ration : G√©n√®re les index des tokens de la s√©quence que l'on cherche √† obtenir √† partir des index obtenus par le Tokenizer et l'utilisation du mod√®le pr√©-entrain√©.
- D√©codage : D√©code les index des tokens en une nouvelle string.

Pour conclure cette partie j'insiste sur le fait que la fonction doit renvoyer un ```dict```.

5. Runner l'API

On arrive enfin √† l'√©tape finale qui va tout simplement consister √† faire tourner en local notre API sur un serveur Uvicorn. Pour cela, il existe deux possibilit√©s.
Vous pouvez rajouter dans le script ces 2 lignes de code :
```py
# Running the API on our local network:

if __name__ == '__main__':    
    uvicorn.run(app, host='127.0.0.1', port=8000)
```
Ou bien, vous pouvez directement lancer le serveur dans le terminal :
```console
uvicorn french_text_to_sql_query:app --reload
```
Au passage, voici le script au complet :

```py
# Import packages 
import uvicorn
import logging
from fastapi import FastAPI
from transformers import AutoModelWithLMHead, AutoTokenizer

app = FastAPI(title='French to SQL translation API ü§ó', description='API for SQL query translation from french text using Hugging Face transformers')

my_logger = logging.getLogger()
my_logger.setLevel(logging.DEBUG)
logging.basicConfig(level=logging.DEBUG, filename='logs.log')

model_trad_fr_to_eng = AutoModelWithLMHead.from_pretrained("Helsinki-NLP/opus-mt-fr-en")

tokenizer_translation = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-fr-en")

tokenizer_sql = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")

model_sql = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")

@app.get('/')
def get_root():

    return {'Message': 'Welcome to the french SQL query translator !'}

@app.get('/get_query/{query}', tags=['query'])
async def text_to_sql_query(query:str):
    
    '''This function allows to convert french text to a SQL query using opus-mt-fr-en transformer for text translation and a t5 base finedtuned on wikiSQL for english to SQL traduction'''
   

    inputs_trad = tokenizer_translation.encode(query, return_tensors="pt")
    outputs_trad = model_trad_fr_to_eng.generate(inputs_trad, max_length=600, num_beams=4, early_stopping=True)

    text_trad = tokenizer_translation.decode(outputs_trad[0]).replace('<pad>','')

    text_to_convert_query = "translate English to SQL: %s </s>" % text_trad
    features = tokenizer_sql([text_to_convert_query], return_tensors='pt')

    output_sql = model_sql.generate(input_ids=features['input_ids'], 
                attention_mask=features['attention_mask'])

    sql_query = tokenizer_sql.decode(output_sql[0]).replace('<pad>','').replace('</s>','')

    return { 'SQL QUERY' : sql_query} 

if __name__ == '__main__':    
    uvicorn.run(app, host='127.0.0.1', port=8000)
```
Une fois tout ceci r√©alis√©, notre script est termin√© et nous n'avons plus qu'√† le faire tourner. Si tout fonctionne correctement, vous devriez voir apparaitre ceci dans le terminal :
```console
INFO:     Started server process [31847]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:33262 - "GET / HTTP/1.1" 200 OK
```
**Attention**: L'ex√©cution peut prendre un peu de temps selon votre connexion internet car il faut dans un premier temps t√©l√©charger les mod√®les.

Il est d√©sormais temps de se rendre sur notre API et de la tester ! Pour cela nous allons nous rendre au dashboard FastApi qui va nous permettre d'envoyer des requ√™tes √† l‚ÄôAPI : [http://127.0.0.1:8000/docs#/](http://127.0.0.1:8000/docs#/)

![](https://user-images.githubusercontent.com/52154100/125428785-3cd376b1-667b-49ad-a92b-e4a53f97365b.png)

6. Test de l'API
7. 
Le moment de v√©rit√© est arriv√© ! Pour v√©rifier que l'API fonctionne correctement nous allons ex√©cuter une requ√™te relativement simple du type ```S√©lectionner les magasins ayant un chiffre d'affaire sup√©rieur √† 100000``` ce qui se traduirait en SQL par la query ```SELECT shops FROM table WHERE turnover > 100 000```. Tout ce que nous faisons reste  exp√©rimental donc ne soyez pas surpris si la query renvoy√©e n'est pas exactement ce dont vous vous attendiez. Mais tout cela reste quand m√™me assez prometteur pour la suite et amusant (enfin c'est mon avis).

![](https://user-images.githubusercontent.com/52154100/125434336-c806462e-b4bc-4b04-a433-41588483c5e2.png)

Comme vous le voyez, j'ai directement ex√©cut√© la requ√™te dans le dashboard de FastApi (mais vous pouvez tr√®s bien l'ex√©cuter dans le terminal) qui nous renverrai ceci :
```console
{
  "SQL QUERY": " SELECT Stores FROM table WHERE Turnover > 100000"
}
```
Le r√©sultat n‚Äôest pas trop mal non ? ü•≥
Apr√®s, comme je vous l'ai dit, ne vous attendez pas √† ce que l'API puisse r√©soudre des query complexes. Dans l'id√©e, si l'on voulait obtenir de meilleures performances il faudrait non pas passer par la traduction fran√ßais-anglais mais directement entrain√©s un mod√®le sur des phrases √©crites en fran√ßais.

## Tout le monde dans le conteneur üê≥ ## 

L'API √©tant fonctionnelle, nous allons faire en sorte de la rendre utilisable par tous. Afin de rendre cela possible, nous allons devoir utiliser Docker. Plus pr√©cis√©ment il va falloir convertir notre application en image Docker. Pour cela, nous allons cr√©er un Dockerfile qui prendra la forme suivante :
```
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7 

WORKDIR /app/

COPY . /app/

RUN pip install torch==1.9.0+cpu -f https://download.pytorch.org/whl/torch_stable.html \
&& pip install transformers[sentencepiece] 

CMD ["python","french_text_to_sql_query.py"]
```
Pour faire simple, le Dockerfile va donner plusieurs instructions √† Docker. Docker va cr√©er un fichier /app dans l'image base ```uvicorn-gunicorn-fastapi:python3.7``` (Notes: Cette image permet d'utiliser FastApi dans un conteneur Docker) puis va copier dans ce fichier tout ce qui se trouve dans le r√©pertoire actif, et installer les diff√©rents packages n√©cessaires. Enfin, on demande √† Docker de lancer notre script python sur le port 8000, et tout √ßa dans un conteneur Docker. 

D√©sormais, nous n‚Äôavons plus qu'√† lancer deux commandes dans notre terminal: 
```console
docker build -t french_sql_query
docker run french_sql_query
```
Comme tout √† l'heure, on se rends √† l'adresse [127.0.0.1:8000/docs#/](127.0.0.1:8000/docs#/) pour voir si tout fonctionne correctement. Si vous voyez le dashboard FastApi, c'est que nous avons r√©ussi √† d√©ployer notre API dans un conteneur Docker üëåüèº.

## We made it ##

Yeaaaaah ! Nous avons d√©ploy√© une API qui permet de traduire du fran√ßaise en une requ√™te SQL ! Si ce n‚Äôest pas cool √ßa !? Merci d'avoir suivi cet article/tutoriel jusqu'au bout. Si besoin, vous pouvez directement t√©l√©charger l'image Docker du projet sur [mon repo Dockerhub](https://hub.docker.com/repository/docker/natsunami/content) üëàüèΩ

On se retrouve bient√¥t pour un nouvel article ! üññ

