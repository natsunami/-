---
layout: post
title: French to SQL query API using transformers | Fast-Api | Docker 
subtitle: Tired to write down SQL queries ? Lazy to learn SQL ? This article might be for you...
cover-img: /assets/img/
thumbnail-img: /assets/img/article french sql query logo.png
share-img: /assets/img/
tags: [SQL, Transformers, Hugging face, query, fast-api, docker]

---
## Introduction ##

Il y a quatre ans, un papier scientifique entraina une profonde r√©volution dans le milieu de l'intelligence artificielle et plus sp√©cifiquement dans le deep learning. En effet, consid√©r√© comme une v√©ritable avanc√©e, le papier [Attention is all you need (2017)](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) de Vaswani, et al., d√©veloppa le concept d'*attention* permettant une am√©lioration significative des performances des neural networks utilis√©s jusqu'√† lors pour des t√¢ches de traitement naturel du language (NLP = Naturel Language Processing). Ainsi, nacquirent les Transformers. Non, je ne parle pas des auto-bots et decepticons se livrant une lutte sans merci et ayant la facult√© de se transformer en voitures, mais bel et bien de neural networks reposant sur le concept d'attention, et tr√®s puissant en  NLP. Petite anecdote, si vous avez remarquez une am√©lioration dans la traduction g√©n√©r√©e par Google trad au cours de cette p√©riode,maintenant vous savez que se sont les transformers √† l'oeuvre !

Depuis la publication, les d√©couvertes et avanc√©es dans l'√©tude des transformers se sont consid√©rablement enrichient, contribuant ainsi au d√©veloppement d'un nombre incroyable de mod√®les utilis√©s pour la r√©solution de t√¢ches de NLP telles que la classification de phrases, l'analyse de sentiments, la traduction mais aussi la g√©n√©ration de texte (Essayez [AI Dungeon](https://play.aidungeon.io/main/landing) pour voir la puissance des mod√®les GPT-2 & 3 et surtout quelques heures de fun) et autres. Gr√¢ce √† [Hugging Face] ü§ó, soci√©t√© francaise üá´üá∑ fond√© en 2016 par Cl√©ment Delangue et Julien Chaumond, il est d√©sormais possible d'impl√©menter le State-of-the-Art du NLP en toute simplicit√©. En effet,avec la cr√©ation de la librairie [transformers](https://huggingface.co/transformers/), de nombreux mod√®les pr√©-entrain√©s sur des t√¢ches sp√©cifiques,avec possibilit√© de les fine-tuner, peuvent √™tre utilis√©s sans etre un crack sur le fonctionnement de ce type de neural network.

Un jour, apr√®s avoir scroll√© de nombreuses minutes sur Linkedin, je me retrouva devant un post de Hugging Face qui faisait √©tat des capacit√©s du mod√®le GPT-Neo, cousin open-source de GPT-3. Ce post m'intrigua fortement, d'autant plus qu'il √©tait mention de la possibilit√© de traduire du texte en requetes SQL. En tant que Data Analyst, le language SQL tient une place fondamentale dans mon m√©tier. Le SQL √©tant partout, il m'est d√©ja arriv√© d'imaginer un monde o√π il serait possible de requeter ses donn√©es directement (e.g: "Quels sont les 10 magasins ayant le chiffre d'affaire le plus elev√© dans l'ordre d√©croissant ?") sans passer par le language SQL. Et bien je crois qu'aujourd'hui ce monde est √† port√© de main et que de plus en plus de solution permettant de requeter des donn√©es de facon textuelles ( = no SQL) seront amen√©es √† etre developp√©es. En effet, m√™me si le SQL est un language extremement r√©pandu, utilis√© non pas seulement par des individus dans la data, il existe bien des personnes n'ayant pas de notions en SQL ( ou qui haissent le language type code) qui pourraient √™tre amen√©es √† r√©aliser des requetes. Ddans ce contexte, 

Bon, tr√™ve de bavardage, il est temps de passer √† l'action et je crois que vous voyez ou je veux en venir...L'API pour traduire du texte en anglais en SQL existe d√©ja (Testez la [ici](https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL) !), l'id√©e n'est pas de la recr√©er, cela n'aurait aucun interet. Mais...en bon francais que je suis, je me suis dit: "Hey ! Mais ca serait vraiment cool de pouvoir directement ecrire en francais üá´üá∑!". Cocorico, j'ai d√©cid√© de cr√©er une API toute simple qui prend en input du texte francais pour la convertir en requete SQL et de la d√©ployer. Voyons tout de suite comment nous allons nous y prendre !

## La recette de cuisine pour l'API ##

Pour d√©buter, vous aurez besoin :
1. 3 oeufs
2. 100 g de fa....Ah d√©sol√©, c'est la recette du gateau au chocolat marmiton ca...

Non, plus s√©rieusement, voici ce dont nous allons vraiment avoir besoin:

### Transformers ### 

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F1200%2F1*Bp8K-_PJrG2NQxLlzk7hlw.png&f=1&nofb=1)

Comme mentionn√© auparavant, nous allons utilis√© la librairie **Transformers** de Hugging Face. La librairie est indispensable puisqu'elle contient les mod√®les pr√©-entrain√©s que nous allons utiliser pour la traduction du francais en SQL.. Pour l'installation, si vous avez deja Tensorflow 2.0 et/ou PyTorch, vous pouvez directement l'installer avec pip (Pour plus de pr√©cisions, la doc d'installation est consultable [ici](https://huggingface.co/transformers/installation.html):
```console
pip install transformers
```
Pour v√©rifier que l'installation s'est bien pass√©, vous pouvez runner la commande suivante dans votre terminal bash:
```console
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
```
Vous devriez voir appara√Ætre ceci:
```console
[{'label': 'POSITIVE', 'score': 0.9998704791069031}]
```

### FastApi ###

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F1023%2F1*du7p50wS_fIsaC_lR18qsg.png&f=1&nofb=1)

[FastApi](https://fastapi.tiangolo.com/) est un framework web qui, comme son nom l'indique, va nous permettre de cr√©er rapidement des API ultra-performante. En trois mots, FastApi c'est: Rapide, simple et robuste. La rapidit√© de FastAPI est possible gr√¢ce √† Pydantic, Starlette et Uvicorn. Pydantic est utilis√© pour la validation des donn√©es et Starlette pour l'outillage, ce qui le rend extr√™mement rapide par rapport √† Flask et lui conf√®re des performances comparables √† celles des API Web √† haut d√©bit en Node ou Go. Il s'agit d'un cadre innovant construit sur Starlette et Uvicorn. Starlette est un framework/toolkit ASGI l√©ger, id√©al pour cr√©er des services asynchrones √† haute performance. Uvicorn est un serveur ASGI rapide comme l'√©clair, construit sur uvloop et httptools. 

Pour installer FastApi, rien de plus simple:
```console
pip install fastapi uvicorn[standard]
```

### Docker ###

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn.1min30.com%2Fwp-content%2Fuploads%2F2018%2F04%2FLogo-Docker.jpg&f=1&nofb=1)

Bon, je pense que je n'ai pas besoin de pr√©senter Docker en long et en large. Pour faire court, Docker va nous permettre de  "containeriser"  notre code ainsi que ses d√©pendances (e.g. Transformers, FastApi) afin notre API puisse etre execut√© sur n'importe quel serveur. Pour cela, nous allons cr√©er un DOCKERFILE et builder l'image DOCKER.

Si Docker n'est pas d√©ja install√©, je vous renvoie √† la doc, qui est tr√®s bien ecrite : [Get Docker](https://docs.docker.com/get-docker/) 
 
## Cr√©ation de l'API ##

Maintenant que nous avons pass√© en revu tout ce dont nous avions besoin pour cr√©er notre API et in fine, la d√©ployer, il est temps de passer √† l'action! Vous allez voir qu'en quelques lignes de code la magie va op√©rer. üßôüèª‚Äç‚ôÄÔ∏è  

### Cr√©ation du script ###

Dans cette partie nous allons montrer comment cr√©er l'API √©tape par √©tape. 

1. Importer les librairies

importer dans notre petit script python les librairies dont nous avons besoin pour notre API. Dans l'ordre, on import tout d'abord FastApi et uvicorn, puis les auto classes  **AutoModelWithLMHead** et **AutoTokenizer** de la librairie transformers que nous utiliserons juste apr√®s et que j'expliquerai plus en d√©tails. La librairie logging n'est pas essentielle ici, elle permet juste d'√©mettre des messages suites √† des √©ven√®ments et ainsi r√©soudre des anomalies.
```py
# Import packages:

from fastapi import FastAPI
import uvicorn
from transformers import AutoModelWithLMHead, AutoTokenizer
#import logging
```
2. Cr√©er l'instance FastApi

Une fois les librairies import√©es, la premi√®re chose √† faire est d'instancier notre application. Pour cela, rien de plus simple :
```py
# Instanciate the app:

app = FastAPI(title='French to SQL translation API ü§ó', description='API for SQL query translation from french text using Hugging Face transformers')

#my_logger = logging.getLogger()
#my_logger.setLevel(logging.DEBUG)
#logging.basicConfig(level=logging.DEBUG, filename='logs.log')
```
FastApi est une classe python qui contient l'ensemble des fonctionnalit√©s pour l'API. De plus, par convention on appellera la variable 'app' mais vous pouvez l'appeler comme bon vous semble. Pour finir, il est possible de renseigner dans les param√®tres le titre ainsi qu'une br√®ve description de l'application, ce qui permettra aux utilisateurs de savoir √† quoi sert l'API.

3. Instanciate transformers models

Cette √©tape est la plus importante dans le script puisque c'est ici que nous allons telecharger les mod√®les pr√©-entrain√©s et les tokenizers associ√©s et les instancier. Pour cela, on utilise les deux classes import√©es pr√©c√©demment:

- AutoModelWithLMHead: Classe de mod√®le qui sera instanci√©e lorsque l'on utilisera la m√©thode de classe AutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path). Il existe une tr√®s grande vari√©t√© de mod√®les qui peuvent etre t√©l√©charger, chacun ayant des sp√©cificit√©s et permettant de r√©sourdre des probl√©matiques diff√©rentes. La liste des mod√®les est consultable [ici](https://huggingface.co/transformers/v3.0.2/model_summary.html) !

- AutoTokenizer: Classe de tokenizer qui sera instanci√©e lorsque l'on utilisera la m√©thode de classe AutoTokenizer.from_pretrained(pretrained_model_name_or_path). Le tokenizer utilis√© est celui mentionn√© par l'utilisateur dans la m√©thode from_pretrained ( e.g. distillert, roberta, t5,...) Petit rappel conernant la tokenization,l'objectif du tokenizer est tout simplement de pr√©traiter le texte. Il va diviser le texte en mots (ou parties de mots, symboles de ponctuation, etc.) que l'on appelle **tokens**. Lors de l'utilisation d'un mod√®le, il faut s'assurer que le tokenizer instanci√© correspond au tokenizer ayant √©t√© utilis√© pour entrainer le mod√®le.
```py
#Download and instanciate vocabulary and Fr-to-En model :
model_trad_fr_to_eng = AutoModelWithLMHead.from_pretrained("Helsinki-NLP/opus-mt-fr-en")
tokenizer_translation = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-fr-en")

#Download and instanciate vocabulary and En-to-SQL model :
tokenizer_sql = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
model_sql = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-wikiSQL")
```
Le code ci-dessus nous permet donc de telecharger et instancier dans un premier temps le mod√®le [opus-mt-fr-en](https://huggingface.co/Helsinki-NLP/opus-mt-fr-en). Ce mod√®le va tout simplement nous permettre de convertir du francais en anglais. Puis on t√©l√©charge et instancie le mod√®le [t5-base-finetuned-wikiSQL](https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL qui va convertire le texte anglais en SQL.

4.D√©finir le *path operation decorator*:

Cette √©tape va faire en sorte que l'API puisse r√©aliser certaines actions ( dans notre cas, traduire le texte en SQL) en communiquant avec elle via des m√©thodes de requetes HTTP. Pour parvenir √† notre fin, on va renseigner √† FastApi le type de m√©thode (e.g. POST, GET, DELETE, PUT,...) et le chemin ( L'endroit/endpoint o√π se fait la requete). Voici un exemple d'operation que l'on pourait r√©aliser:
```py
@app.get('/')
def get_root():

    return {'Message': 'Welcome to the french SQL query translator !'}
```
Le ``` @app.get('/')``` dit √† FastApi que la fonction juste en dessous est charg√©e de traiter les requetes qui vont vers le chemin ```/``` et qui utilisent la m√©thode GET, ce qui renverra le dict ```{'Message': 'Welcome to the french SQL query translator !'}```

Maintenant que nous comprenons mieux comment r√©aliser des op√©rations, nous allons pouvoir √©crire la fonction qui va traduire le texte en francais en SQL: 
```py
@app.get('/get_query/{query}', tags=['query'])
async def text_to_sql_query(query:str):
    
    '''This function allows to convert french text to a SQL query using opus-mt-fr-en transformer for text translation and a t5 base finedtuned on wikiSQL for english to SQL traduction'''
   

    inputs_trad = tokenizer_translation.encode(query, return_tensors="pt")
    outputs_trad = model_trad_fr_to_eng.generate(inputs_trad, max_length=600, num_beams=4, early_stopping=True)

    text_trad = tokenizer_translation.decode(outputs_trad[0]).replace('<pad>','')

    text_to_convert_query = "translate English to SQL: %s </s>" % text_trad
    features = tokenizer_sql([text_to_convert_query], return_tensors='pt')

    output_sql = model_sql.generate(input_ids=features['input_ids'], 
                attention_mask=features['attention_mask'])

    sql_query = tokenizer_sql.decode(output_sql[0]).replace('<pad>','').replace('</s>','')

    return { 'SQL QUERY' : sql_query} 
```

```py
if __name__ == '__main__':    
    uvicorn.run(app, host='127.0.0.1', port=8000)
```
